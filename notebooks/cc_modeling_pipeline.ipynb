{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Production-Grade Customer Churn Modeling Pipeline\n", "**Dataset**: `customers.csv`\n", "\n", "This notebook implements a robust, production-ready machine learning pipeline for customer churn prediction. It incorporates best practices including:\n", "- **Data Leakage Prevention**: Removing features recorded *after* the churn event.\n", "- **Proper Evaluation**: Focusing on ROC-AUC, PR-AUC, and Recall for imbalanced data.\n", "- **Robust Pipelines**: Consolidating preprocessing and modeling into a single `sklearn` Pipeline to prevent data leakage during cross-validation.\n", "- **Hyperparameter Tuning**: Using `RandomizedSearchCV` for efficient optimization.\n", "- **Explainability**: Using SHAP (SHapley Additive exPlanations) for transparent model interpretation.\n", "- **Business Strategy**: Actionable retention insights based on model outputs.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install -q scikit-learn pandas numpy matplotlib seaborn xgboost shap\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Imports & Configuration\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings\n", "from pathlib import Path\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import (\n", "    roc_auc_score, average_precision_score, recall_score,\n", "    precision_score, f1_score, accuracy_score,\n", "    confusion_matrix, ConfusionMatrixDisplay,\n", "    roc_curve, precision_recall_curve, auc\n", ")\n", "\n", "import shap\n", "from xgboost import XGBClassifier\n", "\n", "warnings.filterwarnings('ignore')\n", "sns.set_theme(style=\"whitegrid\")\n", "plt.rcParams[\"figure.figsize\"] = (10, 6)\n", "\n", "RANDOM_STATE = 42\n", "np.random.seed(RANDOM_STATE)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Data Loading & Leakage Audit\n", "**Data Leakage** occurs when a model is trained using information that won't be available at prediction time. \n", "For churn, features like `last_active`, `days_since_last_login`, or `month_last_active` are highly leaky because a customer who churned naturally stops logging in. Using these allows the model to \"cheat\" by detecting the *result* of churn rather than *predicting* it in advance.\n", "\n", "We will proactively drop these leaky features.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_PATH = Path(\"../data/customers.csv\")\n", "df = pd.read_csv(DATA_PATH)\n", "\n", "# Target Variable\n", "TARGET = \"churned\"\n", "\n", "print(f\"Original shape: {df.shape}\")\n", "\n", "# ----- LEAKAGE AUDIT & REMOVAL -----\n", "# Features directly caused by the churn event\n", "leaky_features = [\"last_active\", \"days_since_last_login\", \"month_last_active\"]\n", "\n", "# IDs and dates that are not predictive or have been parsed\n", "# We will extract the month/year from signup_date, then drop it.\n", "df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], errors=\"coerce\")\n", "df[\"signup_month\"] = df[\"signup_date\"].dt.month\n", "df[\"signup_year\"] = df[\"signup_date\"].dt.year\n", "\n", "drop_cols = leaky_features + [\"customer_id\", \"signup_date\"]\n", "existing_drop_cols = [c for c in drop_cols if c in df.columns]\n", "\n", "df = df.drop(columns=existing_drop_cols)\n", "print(f\"Shape after removing leaky features/IDs: {df.shape}\")\n", "df.head(3)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Train-Test Split\n", "We use a **Stratified Split** to ensure both the training and testing sets maintain the underlying 77/23 class ratio. Splitting *before* any preprocessing guarantees no data leakage (e.g., target statistics bleeding into the training data through scalers or imputers).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df.drop(columns=[TARGET])\n", "y = df[TARGET]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, \n", "    test_size=0.2, \n", "    random_state=RANDOM_STATE, \n", "    stratify=y  # Essential for imbalanced datasets\n", ")\n", "\n", "neg, pos = (y_train == 0).sum(), (y_train == 1).sum()\n", "scale_pos_weight = neg / pos\n", "\n", "print(f\"Training Set: {X_train.shape[0]} rows (Churn Ratio: {y_train.mean():.2%})\")\n", "print(f\"Testing Set:  {X_test.shape[0]} rows (Churn Ratio: {y_test.mean():.2%})\")\n", "print(f\"Class Imbalance Ratio (Neg/Pos): {scale_pos_weight:.2f}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Preprocessing Pipeline\n", "We build a robust `ColumnTransformer` embedded inside an `sklearn.pipeline.Pipeline`. \n", "- **Numeric Features**: Median imputation (robust to outliers) + Standard Scaling.\n", "- **Categorical Features**: Constant imputation + One-Hot Encoding (preventing dummy trap issues natively inside tree models, while `handle_unknown='ignore'` guards against unseen test categories).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n", "categorical_features = X_train.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n", "\n", "numeric_transformer = Pipeline(steps=[\n", "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n", "    (\"scaler\", StandardScaler())\n", "])\n", "\n", "categorical_transformer = Pipeline(steps=[\n", "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n", "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n", "])\n", "\n", "preprocessor = ColumnTransformer(\n", "    transformers=[\n", "        (\"num\", numeric_transformer, numeric_features),\n", "        (\"cat\", categorical_transformer, categorical_features)\n", "    ]\n", ")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Model Training & Hyperparameter Tuning\n", "We use **XGBoost**, which natively handles tabular capabilities exceptionally well.\n", "- **`scale_pos_weight`**: Accounts for the 3.3:1 imbalance natively, optimizing the loss function to penalize missed churners heavily.\n", "- **`RandomizedSearchCV`**: Tunes max_depth, learning rate, and subsampling efficiently through 3-fold cross-validation.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Define the base pipeline\n", "pipeline = Pipeline(steps=[\n", "    (\"preprocessor\", preprocessor),\n", "    (\"classifier\", XGBClassifier(\n", "        scale_pos_weight=scale_pos_weight, # Handles class imbalance\n", "        eval_metric=\"logloss\",\n", "        random_state=RANDOM_STATE,\n", "        n_jobs=-1\n", "    ))\n", "])\n", "\n", "# 2. Define Hyperparameter space\n", "param_grid = {\n", "    \"classifier__n_estimators\": [100, 200, 300],\n", "    \"classifier__max_depth\": [3, 5, 7],\n", "    \"classifier__learning_rate\": [0.01, 0.05, 0.1],\n", "    \"classifier__subsample\": [0.8, 1.0],\n", "    \"classifier__colsample_bytree\": [0.8, 1.0]\n", "}\n", "\n", "# 3. Stratified K-Fold for robust CV\n", "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n", "\n", "# 4. RandomizedSearchCV optimizing for PR-AUC (best for imbalanced classification)\n", "grid_search = RandomizedSearchCV(\n", "    pipeline,\n", "    param_distributions=param_grid,\n", "    n_iter=10,             # Keep low for notebook execution speed\n", "    scoring=\"average_precision\", # PR-AUC Score \n", "    cv=cv,\n", "    verbose=1,\n", "    random_state=RANDOM_STATE,\n", "    n_jobs=-1\n", ")\n", "\n", "grid_search.fit(X_train, y_train)\n", "\n", "print(f\"Best parameters: {grid_search.best_params_}\")\n", "best_model = grid_search.best_estimator_\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Model Evaluation\n", "For imbalanced datasets, **Accuracy is a misleading metric**. Instead, we focus on:\n", "- **ROC-AUC**: Ability to rank churners higher than non-churners.\n", "- **PR-AUC (Average Precision)**: Quality of the positive (churn) predictions.\n", "- **Recall**: The percentage of actual churners we successfully identified.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Predictions\n", "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n", "\n", "# Default threshold 0.5 predictions\n", "y_pred = best_model.predict(X_test)\n", "\n", "metrics = {\n", "    \"ROC-AUC\": roc_auc_score(y_test, y_pred_proba),\n", "    \"PR-AUC (Avg Precision)\": average_precision_score(y_test, y_pred_proba),\n", "    \"Recall\": recall_score(y_test, y_pred),\n", "    \"Precision\": precision_score(y_test, y_pred),\n", "    \"F1-Score\": f1_score(y_test, y_pred),\n", "    \"Accuracy\": accuracy_score(y_test, y_pred)\n", "}\n", "\n", "print(\"--- Test Set Performance (Threshold=0.5) ---\")\n", "for k, v in metrics.items():\n", "    print(f\"{k:<25}: {v:.4f}\")\n", "\n", "# Plot Confusion Matrix\n", "fig, ax = plt.subplots(figsize=(6, 5))\n", "ConfusionMatrixDisplay.from_predictions(\n", "    y_test, y_pred, \n", "    display_labels=[\"Retained\", \"Churned\"], \n", "    cmap=\"Blues\", ax=ax, colorbar=False\n", ")\n", "ax.set_title(\"Confusion Matrix (Test Set)\")\n", "ax.grid(False)\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 6.1 Performance Curves (ROC & Precision-Recall)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n", "\n", "# ROC Curve\n", "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n", "axes[0].plot(fpr, tpr, color=\"#2ecc71\", lw=2, label=f\"AUC = {metrics['ROC-AUC']:.3f}\")\n", "axes[0].plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n", "axes[0].set_title(\"Receiver Operating Characteristic (ROC)\", fontweight=\"bold\")\n", "axes[0].set_xlabel(\"False Positive Rate\")\n", "axes[0].set_ylabel(\"True Positive Rate\")\n", "axes[0].legend(loc=\"lower right\")\n", "\n", "# PR Curve\n", "prec, rec, _ = precision_recall_curve(y_test, y_pred_proba)\n", "axes[1].plot(rec, prec, color=\"#e74c3c\", lw=2, label=f\"PR-AUC = {metrics['PR-AUC (Avg Precision)']:.3f}\")\n", "# Baseline PR is the proportion of positives\n", "baseline = y_test.mean()\n", "axes[1].axhline(baseline, color=\"gray\", linestyle=\"--\", label=f\"Baseline ({baseline:.3f})\")\n", "axes[1].set_title(\"Precision-Recall Curve\", fontweight=\"bold\")\n", "axes[1].set_xlabel(\"Recall\")\n", "axes[1].set_ylabel(\"Precision\")\n", "axes[1].legend(loc=\"upper right\")\n", "\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Decision Threshold Tuning\n", "The default classification threshold evaluates at `0.5`. However, in business scenarios where the cost of a missed churner (False Negative) is high, we can lower the threshold to increase Recall at the expense of Precision.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["thresholds = np.linspace(0.1, 0.9, 50)\n", "precisions, recalls, f1_scores = [], [], []\n", "\n", "for t in thresholds:\n", "    y_hat = (y_pred_proba >= t).astype(int)\n", "    precisions.append(precision_score(y_test, y_hat, zero_division=0))\n", "    recalls.append(recall_score(y_test, y_hat))\n", "    f1_scores.append(f1_score(y_test, y_hat))\n", "\n", "plt.figure(figsize=(10, 5))\n", "plt.plot(thresholds, precisions, label=\"Precision\", color=\"#3498db\", lw=2)\n", "plt.plot(thresholds, recalls, label=\"Recall\", color=\"#e74c3c\", lw=2)\n", "plt.plot(thresholds, f1_scores, label=\"F1 Score\", color=\"#f39c12\", lw=2)\n", "\n", "best_f1_idx = np.argmax(f1_scores)\n", "best_thresh = thresholds[best_f1_idx]\n", "\n", "plt.axvline(best_thresh, color=\"gray\", linestyle=\"--\", label=f\"Max F1 Threshold ({best_thresh:.2f})\")\n", "plt.title(\"Metrics Across Decision Thresholds\", fontweight=\"bold\")\n", "plt.xlabel(\"Probability Threshold\")\n", "plt.ylabel(\"Score\")\n", "plt.legend()\n", "plt.show()\n", "\n", "print(f\"To maximize F1-Score, set the prediction threshold to: {best_thresh:.2f}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Model Explainability (SHAP & Feature Importance)\n", "Black-box models require interpretability for business trust. We extract the generated feature names from the `ColumnTransformer` and use `Feature Importances` and `SHAP` values to explain what drives churn.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Extract mapped feature names from Pipeline\n", "ohe_features = best_model.named_steps[\"preprocessor\"].named_transformers_[\"cat\"].named_steps[\"onehot\"].get_feature_names_out(categorical_features)\n", "all_feature_names = numeric_features + list(ohe_features)\n", "\n", "# 2. Plot Global Feature Importances\n", "xgb_model = best_model.named_steps[\"classifier\"]\n", "importances = xgb_model.feature_importances_\n", "\n", "imp_df = pd.DataFrame({\"Feature\": all_feature_names, \"Importance\": importances})\n", "imp_df = imp_df.sort_values(by=\"Importance\", ascending=False).head(15)\n", "\n", "plt.figure(figsize=(10, 6))\n", "sns.barplot(data=imp_df, x=\"Importance\", y=\"Feature\", palette=\"viridis\")\n", "plt.title(\"Top 15 Most Important Features (XGBoost Gain)\", fontweight=\"bold\")\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 3. SHAP Summary Plot\n", "# We must pass the preprocessed data to the SHAP explainer\n", "X_train_preprocessed = best_model.named_steps[\"preprocessor\"].transform(X_train)\n", "X_test_preprocessed = best_model.named_steps[\"preprocessor\"].transform(X_test)\n", "\n", "# Optional: Convert to DataFrame for pretty feature names in SHAP plot\n", "X_test_sh = pd.DataFrame(X_test_preprocessed, columns=all_feature_names)\n", "\n", "# Initialize explainer\n", "explainer = shap.TreeExplainer(xgb_model)\n", "shap_values = explainer.shap_values(X_test_sh)\n", "\n", "plt.title(\"SHAP Feature Impacts on Churn Prediction\")\n", "shap.summary_plot(shap_values, X_test_sh, plot_type=\"dot\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Business Interpretation & Retention Strategy\n", "\n", "Based on the pipeline evaluation and SHAP explanations, the machine learning model reveals the following actionable business insights:\n", "\n", "### Interpretation of Results\n", "1. **The Leakage Audit Restored Validity**: By removing metrics like `days_since_last_login` and `last_active`, the model now predicts churn *proactively* based on engagement and behavioral signals rather than simply recognizing inactive accounts.\n", "2. **Class Imbalance Addressed**: The `scale_pos_weight` parameter forced the model to prioritize churners. Combined with **threshold tuning**, the business can now actively choose to flag more at-risk users by lowering the threshold (e.g., to ~0.35) to boost the Recall rate.\n", "3. **Key Drivers of Churn**: \n", "    - *(Referencing the SHAP summary plot)*: The visualizations will show exactly which factors push a customer's probability assigned near 1 (Churn) vs 0 (Retained). E.g., low `avg_session_minutes`, a high amount of `num_tickets_90d`, or specific `plan` tiers.\n", "\n", "### Recommended Retention Strategy\n", "* How to use this model in production:\n", "1. **Weekly Scoring Batch**: Run the active customer base through this pipeline every week to generate a \"Churn Risk Score\" (`predict_proba`).\n", "2. **Targeted Interventions**:\n", "    - **High Risk (Top 10% Probability)**: Trigger hands-on Customer Success outreach or aggressive discounts.\n", "    - **Medium Risk**: Enroll in automated re-engagement email drip campaigns highlighting features they haven't used recently.\n", "3. **Product Feedback Loop**: If the SHAP analysis shows `payment_failures_180d` is a massive driver of churn, the business should invest engineering resources into smoother dunning and payment retry processes. If support wait times (`num_tickets_90d`) drive churn, escalate support SLA protocols.\n", "\n"]}]}