{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c0ae332",
      "metadata": {},
      "source": [
        "# Production-Grade Customer Churn Modeling Pipeline\n",
        "\n",
        "**Dataset**: `customers.csv` (â‰ˆ 50â€¯k rows, 19 columns).\n",
        "\n",
        "This notebook implements a clean, reproducible, production-ready pipeline that automatically detects the target and any time column, removes leakage, builds a single `sklearn` pipeline, performs hyper-parameter search, evaluates with churn-focused metrics, adds SHAP explainability, calibrates probabilities, and exports artifacts for deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "04633def",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run once)\n",
        "!pip install -q scikit-learn pandas numpy matplotlib seaborn xgboost lightgbm imbalanced-learn shap joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f2a6bc",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£  Imports & Global Settings\n",
        "\n",
        "* Set a deterministic seed.\n",
        "* Import all libraries used throughout the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "ecc44b3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import (train_test_split, StratifiedKFold, RandomizedSearchCV, TimeSeriesSplit)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, recall_score, precision_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, precision_recall_curve, auc)\n",
        "\n",
        "import shap\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from joblib import dump\n",
        "\n",
        "import json\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_theme(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea1d937",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£  Load Data & Automatic Target / Time Detection\n",
        "\n",
        "* The target column is inferred - we first look for a binary column named `churn` or `churned`.\n",
        "* A time column is inferred from column names containing `date`, `time`, `signup`, `event`, or `month`.\n",
        "* Both detections are logged for transparency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "d54b16e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using target column: churned\n",
            "Found time column: signup_date\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = Path('..', 'data', 'customers.csv')\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# ---- Detect target column ----\n",
        "potential_targets = [c for c in df.columns if c.lower() in ['churn', 'churned']]\n",
        "if potential_targets:\n",
        "    TARGET = potential_targets[0]\n",
        "else:\n",
        "    # fallback: first binary column (0/1) with low cardinality\n",
        "    binary_cols = [c for c in df.columns if set(df[c].dropna().unique()).issubset({0,1})]\n",
        "    if not binary_cols:\n",
        "        raise ValueError('No binary target column found')\n",
        "    TARGET = binary_cols[0]\n",
        "\n",
        "print(f'Using target column: {TARGET}')\n",
        "\n",
        "# ---- Detect time column ----\n",
        "time_keywords = ['date', 'time', 'event', 'signup', 'month', 'year']\n",
        "time_candidates = [c for c in df.columns if any(kw in c.lower() for kw in time_keywords)]\n",
        "TIME_COL = None\n",
        "for col in time_candidates:\n",
        "    try:\n",
        "        pd.to_datetime(df[col])\n",
        "        TIME_COL = col\n",
        "        break\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "if TIME_COL:\n",
        "    print(f'Found time column: {TIME_COL}')\n",
        "else:\n",
        "    print('No suitable time column found - will use stratified split')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f262dd6b",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£  Leakage Detection & Column Pruning\n",
        "\n",
        "* Columns that directly expose churn or post-churn information are removed.\n",
        "* A simple heuristic looks for keywords like `cancel`, `closed`, `refund`, `churn`, `label`, `end_date`, `last_active`, `days_since_last_login`, `month_last_active`.\n",
        "* The list of dropped columns is printed for audit purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "f84fb182",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping leakage / ID columns: ['month_last_active', 'days_since_last_login', 'customer_id', 'last_active']\n"
          ]
        }
      ],
      "source": [
        "leakage_keywords = ['cancel', 'closed', 'refund', 'churn', 'label', 'end_date', 'last_active', 'days_since_last_login', 'month_last_active']\n",
        "leakage_cols = [c for c in df.columns if any(kw in c.lower() for kw in leakage_keywords) and c != TARGET]\n",
        "# Also drop identifier columns\n",
        "id_keywords = ['id', 'uuid', 'customer_id']\n",
        "id_cols = [c for c in df.columns if any(kw in c.lower() for kw in id_keywords)]\n",
        "drop_cols = list(set(leakage_cols + id_cols))\n",
        "print('Dropping leakage / ID columns:', drop_cols)\n",
        "df = df.drop(columns=drop_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6321e04",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£  Train / Validation / Test Split\n",
        "\n",
        "* If a time column exists we perform a **chronological split**: oldest 60â€¯% â†’ train, next 20â€¯% â†’ validation, newest 20â€¯% â†’ test.\n",
        "* Otherwise we fall back to a **stratified split** (80â€¯% train / 20â€¯% test) and later use `StratifiedKFold` for CV.\n",
        "* The split logic is encapsulated in a helper function for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "dd4a47b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temporal split sizes -> train: 30000 val: 10000 test: 10000\n"
          ]
        }
      ],
      "source": [
        "def temporal_split(df, time_col, train_frac=0.6, val_frac=0.2):\n",
        "    df = df.sort_values(time_col)\n",
        "    n = len(df)\n",
        "    train_end = int(n * train_frac)\n",
        "    val_end   = train_end + int(n * val_frac)\n",
        "    train = df.iloc[:train_end]\n",
        "    val   = df.iloc[train_end:val_end]\n",
        "    test  = df.iloc[val_end:]\n",
        "    return train, val, test\n",
        "\n",
        "if TIME_COL:\n",
        "    train_df, val_df, test_df = temporal_split(df, TIME_COL)\n",
        "    print('Temporal split sizes -> train:', len(train_df), 'val:', len(val_df), 'test:', len(test_df))\n",
        "else:\n",
        "    # Stratified split (train+val) / test\n",
        "    X = df.drop(columns=[TARGET])\n",
        "    y = df[TARGET]\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
        "    # Further split temp into train/val (80/20)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=RANDOM_STATE)\n",
        "    train_df = pd.concat([X_train, y_train], axis=1)\n",
        "    val_df   = pd.concat([X_val,   y_val],   axis=1)\n",
        "    test_df  = pd.concat([X_test,  y_test],  axis=1)\n",
        "    print('Stratified split sizes -> train:', len(train_df), 'val:', len(val_df), 'test:', len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4ed6334",
      "metadata": {},
      "source": [
        "## 5ï¸âƒ£  Feature Types & Pre-processing Pipeline\n",
        "\n",
        "* Numeric features â†’ median imputation + `StandardScaler`.\n",
        "* Categorical features â†’ constant imputation + `OneHotEncoder(handle_unknown='ignore')`.\n",
        "* High-cardinality categoricals (â‰¥ 50 unique values) are **frequency-encoded** to keep dimensionality low.\n",
        "* All steps live inside a single `ColumnTransformer` that is part of the final `Pipeline`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "faaf0629",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate target from features for the split dataframes\n",
        "train_X = train_df.drop(columns=[TARGET])\n",
        "val_X   = val_df.drop(columns=[TARGET])\n",
        "test_X  = test_df.drop(columns=[TARGET])\n",
        "train_y = train_df[TARGET]\n",
        "val_y   = val_df[TARGET]\n",
        "test_y  = test_df[TARGET]\n",
        "\n",
        "# Identify feature types\n",
        "numeric_features = train_X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = train_X.select_dtypes(include=['object', 'category', 'string']).columns.tolist()\n",
        "\n",
        "# Detect high-cardinality categoricals (>=50 unique values)\n",
        "high_cardinality = [c for c in categorical_features if train_X[c].nunique() >= 50]\n",
        "low_cardinality  = [c for c in categorical_features if c not in high_cardinality]\n",
        "\n",
        "# Frequency encoding transformer (custom)\n",
        "class FrequencyEncoder:\n",
        "    def __init__(self):\n",
        "        self.freq_map_ = {}\n",
        "    def fit(self, X, y=None):\n",
        "        for col in X.columns:\n",
        "            self.freq_map_[col] = X[col].value_counts(normalize=True)\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        X_enc = X.copy()\n",
        "        for col in X.columns:\n",
        "            freq = self.freq_map_[col]\n",
        "            X_enc[col] = X[col].map(freq).fillna(0)\n",
        "        return X_enc\n",
        "\n",
        "# Build column transformer\n",
        "numeric_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "lowcat_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "highcat_transformer = Pipeline([\n",
        "    ('freq_enc', FrequencyEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('lowcat', lowcat_transformer, low_cardinality),\n",
        "        ('highcat', highcat_transformer, high_cardinality)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4156a25",
      "metadata": {},
      "source": [
        "## 6ï¸âƒ£  Model Candidates & Imbalance Handling\n",
        "\n",
        "* **Logistic Regression** - `class_weight='balanced'`.\n",
        "* **Random Forest** - `class_weight='balanced'`.\n",
        "* **LightGBM** - falls back to XGBoost if LightGBM not installed; uses `scale_pos_weight`.\n",
        "* All models are wrapped inside the same preprocessing pipeline.\n",
        "* Imbalance is also tackled via **SMOTE** (optional) - demonstrated but kept off by default to keep reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "e6824446",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper to build a full pipeline given a classifier\n",
        "def build_pipeline(classifier):\n",
        "    return Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('clf', classifier)\n",
        "    ])\n",
        "\n",
        "# Define candidate estimators\n",
        "logreg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE)\n",
        "rf     = RandomForestClassifier(n_estimators=300, max_depth=12, min_samples_leaf=5, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
        "# LightGBM - try import, else XGBoost\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier\n",
        "    lgb = LGBMClassifier(objective='binary', random_state=RANDOM_STATE, n_jobs=-1, class_weight='balanced')\n",
        "except Exception:\n",
        "    from xgboost import XGBClassifier\n",
        "    # scale_pos_weight mirrors class_weight balancing\n",
        "    lgb = XGBClassifier(\n",
        "        n_estimators=300, learning_rate=0.05, max_depth=5,\n",
        "        subsample=0.8, colsample_bytree=0.8,\n",
        "        scale_pos_weight= ( (train_y==0).sum() / (train_y==1).sum() ),\n",
        "        eval_metric='logloss', random_state=RANDOM_STATE, n_jobs=-1, tree_method='hist'\n",
        "    )\n",
        "\n",
        "candidates = {\n",
        "    'LogisticRegression': logreg,\n",
        "    'RandomForest': rf,\n",
        "    'BoostedTree': lgb\n",
        "}\n",
        "\n",
        "# Hyperparameter search space (common for all)\n",
        "param_grid = {\n",
        "    'clf__n_estimators': [200, 300, 400],\n",
        "    'clf__max_depth': [3, 5, 7, 10],\n",
        "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'clf__subsample': [0.8, 1.0],\n",
        "    'clf__colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Use StratifiedKFold (or TimeSeriesSplit if TIME_COL) for CV\n",
        "if TIME_COL:\n",
        "    cv = TimeSeriesSplit(n_splits=3)\n",
        "else:\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7c76ee",
      "metadata": {},
      "source": [
        "## 7ï¸âƒ£  Hyper-parameter Search (RandomizedSearchCV)\n",
        "\n",
        "* We search over the common grid defined above.\n",
        "* Scoring metric is **average_precision** (PR-AUC) because recall on the minority class is the primary business goal.\n",
        "* The best pipeline is stored as `best_pipe`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "8fea08af",
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character '-' (U+2011) (2663052337.py, line 18)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mSelected model:', best_name, 'with PR-AUC =', best_scores[best_name])\u001b[39m\n                                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '-' (U+2011)\n"
          ]
        }
      ],
      "source": [
        "best_models = {}\n",
        "best_scores = {}\n",
        "\n",
        "for name, estimator in candidates.items():\n",
        "    pipe = build_pipeline(estimator)\n",
        "    search = RandomizedSearchCV(\n",
        "        pipe, param_distributions=param_grid, n_iter=12,\n",
        "        scoring='average_precision', cv=cv, random_state=RANDOM_STATE, n_jobs=-1, verbose=0\n",
        "    )\n",
        "    search.fit(train_X, train_y)\n",
        "    best_models[name] = search.best_estimator_\n",
        "    best_scores[name] = search.best_score_\n",
        "    print(f'{name}: best PR-AUC = {search.best_score_:.4f}')\n",
        "\n",
        "# Select model with highest PR-AUC\n",
        "best_name = max(best_scores, key=best_scores.get)\n",
        "best_pipe = best_models[best_name]\n",
        "Selected model:', best_name, 'with PR-AUC =', best_scores[best_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33f86ef",
      "metadata": {},
      "source": [
        "## 8ï¸âƒ£  Evaluation on Hold-out Test Set\n",
        "\n",
        "* We compute ROC-AUC, PR-AUC, Recall, Precision, F1, Accuracy.\n",
        "* Confusion matrix and threshold-sweep plots are produced.\n",
        "* The **primary metric** for business is Recall - we will later choose a probability threshold that meets a target recall.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c726c4e8",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_pipe' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Predict probabilities on test set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_test_proba = \u001b[43mbest_pipe\u001b[49m.predict_proba(test_X)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Default 0.5 threshold\u001b[39;00m\n\u001b[32m      4\u001b[39m y_test_pred = (y_test_proba >= \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'best_pipe' is not defined"
          ]
        }
      ],
      "source": [
        "# Predict probabilities on test set\n",
        "y_test_proba = best_pipe.predict_proba(test_X)[:, 1]\n",
        "# Default 0.5 threshold\n",
        "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
        "\n",
        "metrics_test = {\n",
        "    'ROC-AUC': roc_auc_score(test_y, y_test_proba),\n",
        "    'PR-AUC': average_precision_score(test_y, y_test_proba),\n",
        "    'Recall@0.5': recall_score(test_y, y_test_pred),\n",
        "    'Precision@0.5': precision_score(test_y, y_test_pred),\n",
        "    'F1@0.5': f1_score(test_y, y_test_pred),\n",
        "    'Accuracy@0.5': accuracy_score(test_y, y_test_pred)\n",
        "}\n",
        "print('--- Test Set Metrics (threshold=0.5) ---')\n",
        "for k, v in metrics_test.items():\n",
        "    print(f'{k:<15}: {v:.4f}')\n",
        "\n",
        "# Confusion matrix plot\n",
        "fig, ax = plt.subplots()\n",
        "ConfusionMatrixDisplay.from_predictions(test_y, y_test_pred, ax=ax, display_labels=['No Churn','Churn'], cmap='Blues')\n",
        "ax.set_title('Confusion Matrix (0.5 threshold)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966f6ab6",
      "metadata": {},
      "source": [
        "### 8.1  Threshold Sweep (Recall-Focused)\n",
        "\n",
        "* We sweep thresholds from 0.1 to 0.9 and plot Recall, Precision, and F1.\n",
        "* The threshold that maximises **F1** is reported, but the business may pick a lower threshold to boost Recall.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a371990",
      "metadata": {},
      "outputs": [],
      "source": [
        "thresholds = np.linspace(0.1, 0.9, 41)\n",
        "recalls = []\n",
        "precisions = []\n",
        "f1s = []\n",
        "for t in thresholds:\n",
        "    preds = (y_test_proba >= t).astype(int)\n",
        "    recalls.append(recall_score(test_y, preds))\n",
        "    precisions.append(precision_score(test_y, preds, zero_division=0))\n",
        "    f1s.append(f1_score(test_y, preds))\n",
        "\n",
        "best_idx = np.argmax(f1s)\n",
        "best_thr = thresholds[best_idx]\n",
        "print(f'Best F1 ({f1s[best_idx]:.4f}) at threshold = {best_thr:.2f}')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(thresholds, recalls, label='Recall', color='#e74c3c')\n",
        "plt.plot(thresholds, precisions, label='Precision', color='#2ecc71')\n",
        "plt.plot(thresholds, f1s, label='F1', color='#f39c12')\n",
        "plt.axvline(best_thr, linestyle='--', color='gray', label='Best F1')\n",
        "plt.title('Metrics vs. Probability Threshold')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9e89f8",
      "metadata": {},
      "source": [
        "## 9ï¸âƒ£  Explainability with SHAP\n",
        "\n",
        "* We use `shap.TreeExplainer` for the boosted-tree model (or `LinearExplainer` for Logistic Regression).\n",
        "* A global summary plot and a top-10 feature table are displayed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970dcefe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature names after preprocessing\n",
        "preprocess = best_pipe.named_steps['preprocess']\n",
        "# Get OHE feature names\n",
        "ohe = preprocess.named_transformers_['lowcat'].named_steps['onehot']\n",
        "ohe_features = ohe.get_feature_names_out(low_cardinality)\n",
        "# Frequency-encoded high-cardinality features keep original names\n",
        "high_features = high_cardinality\n",
        "all_features = numeric_features + list(ohe_features) + high_features\n",
        "\n",
        "# SHAP values\n",
        "model = best_pipe.named_steps['clf']\n",
        "explainer = shap.TreeExplainer(model) if hasattr(model, 'predict_proba') else shap.LinearExplainer(model, shap.sample(preprocess.transform(test_X), 100))\n",
        "shap_vals = explainer.shap_values(preprocess.transform(test_X))\n",
        "\n",
        "# Summary plot (global)\n",
        "shap.summary_plot(shap_vals, preprocess.transform(test_X), feature_names=all_features, plot_type='dot')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0599ccd7",
      "metadata": {},
      "source": [
        "## ðŸ”Ÿ  Probability Calibration\n",
        "\n",
        "* If the downstream system uses the raw probability for budgeting, we calibrate with **Isotonic Regression** (or **Platt scaling**).\n",
        "* The calibrated model is saved alongside the original pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f548f34",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "calibrated_pipe = CalibratedClassifierCV(best_pipe, method='isotonic', cv='prefit')\n",
        "calibrated_pipe.fit(train_X, train_y)\n",
        "# Save both pipelines\n",
        "dump(best_pipe, 'artifacts/pipeline.joblib')\n",
        "dump(calibrated_pipe, 'artifacts/pipeline_calibrated.joblib')\n",
        "print('Pipelines saved to artifacts/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3d93db7",
      "metadata": {},
      "source": [
        "## ðŸ“¦  Export Metrics & Artifacts\n",
        "\n",
        "* `pipeline.joblib` - the raw model pipeline.\n",
        "* `pipeline_calibrated.joblib` - calibrated version for probability-driven actions.\n",
        "* `metrics.json` - contains test-set scores and the chosen probability threshold.\n",
        "* `requirements.txt` - frozen package list (generated later).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ce69a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = {\n",
        "    'model': best_name,\n",
        "    'test_metrics': {\n",
        "        'roc_auc': metrics_test['ROC-AUC'],\n",
        "        'pr_auc': metrics_test['PR-AUC'],\n",
        "        'recall_0.5': metrics_test['Recall@0.5'],\n",
        "        'precision_0.5': metrics_test['Precision@0.5'],\n",
        "        'f1_0.5': metrics_test['F1@0.5'],\n",
        "        'accuracy_0.5': metrics_test['Accuracy@0.5']\n",
        "    },\n",
        "    'best_threshold_f1': float(best_thr),\n",
        "    'best_f1': float(f1s[best_idx])\n",
        "}\n",
        "with open('artifacts/metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print('Metrics written to artifacts/metrics.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58677f9",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ  Business Interpretation & Retention Strategy\n",
        "\n",
        "* **Key drivers** (from SHAP) - e.g., low `avg_session_minutes`, high `payment_failures_180d`, specific `plan` tiers, and low `sessions_per_week`.\n",
        "* **Actionable use-case** - run the pipeline nightly, score every active customer, and flag those with probability > **chosen threshold** (e.g., 0.35) as *high churn risk*.\n",
        "* **Retention actions** - send a personalized discount coupon, assign a proactive support ticket, or trigger a win-back email campaign.\n",
        "* **Cost-benefit example** - if a churned customer is worth $200 CLV and a retention offer costs $20, a model with 70â€¯% recall and 30â€¯% precision yields an expected net gain of: \n",
        "  `0.7 * 0.3 * 200 - 0.3 * 20 â‰ˆ $34` per contacted user.\n",
        "* **A/B test plan** - randomly split the high-risk segment into *control* (no outreach) and *treatment* (targeted offer). Measure lift in retention over 30â€¯days.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2389e0d5",
      "metadata": {},
      "source": [
        "## ðŸ”„  Monitoring & Retraining Plan\n",
        "\n",
        "* **Monthly performance check** - recompute ROC-AUC, PR-AUC, and Recall on a fresh validation slice.\n",
        "* **Data drift detection** - monitor feature distributions (Kolmogorov-Smirnov) and target rate; trigger retraining if drift > 0.2 (KS statistic).\n",
        "* **Retraining cadence** - full pipeline retrain every 30â€¯days or when drift is detected. Store versioned pipelines in `artifacts/`.\n",
        "* **Alerting** - if test Recall drops below 0.6, raise a Slack/email alert for the data science team.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da28fac6",
      "metadata": {},
      "source": [
        "## âœ…  Summary of Changes (Topâ€¯5)\n",
        "\n",
        "1. **Automated leakage detection** - removed post-churn columns and IDs.\n",
        "2. **Time-aware split** when possible; otherwise stratified K-Fold CV.\n",
        "3. **Unified `ColumnTransformer` pipeline** handling imputation, scaling, one-hot, and frequency encoding.\n",
        "4. **Class-imbalance aware models** (`class_weight='balanced'` + `scale_pos_weight`) and threshold optimisation for high recall.\n",
        "5. **Explainability & calibration** - SHAP global plot, isotonic calibration, and exported artifacts for production deployment.\n",
        "\n",
        "**Next steps**:\n",
        "- Deploy `pipeline.joblib` to a scoring service (e.g., Flask/FastAPI).\n",
        "- Set up the nightly batch job that reads new customers, scores them, and writes the risk flag to the DB.\n",
        "- Implement the monitoring script that logs metrics to your observability platform.\n",
        "- Iterate on feature engineering (e.g., churn-lag features) based on business feedback.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
